{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook used to replicate the LeNet-5 model used in handwriting analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The original publication is: Lecun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278–2324. doi:10.1109/5.726791 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The first few replications will follow tutorials: https://medium.datadriveninvestor.com/architecture-implementation-of-lenet-from-scratch-in-pytorch-709cc38c00a9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchinfo import summary\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (linear1): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (linear2): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (tanh): Tanh()\n",
      "  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "output.shape :  torch.Size([64, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LeNet                                    [64, 10]                  --\n",
       "├─Conv2d: 1-1                            [64, 6, 28, 28]           156\n",
       "├─Tanh: 1-2                              [64, 6, 28, 28]           --\n",
       "├─AvgPool2d: 1-3                         [64, 6, 14, 14]           --\n",
       "├─Conv2d: 1-4                            [64, 16, 10, 10]          2,416\n",
       "├─Tanh: 1-5                              [64, 16, 10, 10]          --\n",
       "├─AvgPool2d: 1-6                         [64, 16, 5, 5]            --\n",
       "├─Conv2d: 1-7                            [64, 120, 1, 1]           48,120\n",
       "├─Tanh: 1-8                              [64, 120, 1, 1]           --\n",
       "├─Linear: 1-9                            [64, 84]                  10,164\n",
       "├─Tanh: 1-10                             [64, 84]                  --\n",
       "├─Linear: 1-11                           [64, 10]                  850\n",
       "==========================================================================================\n",
       "Total params: 61,706\n",
       "Trainable params: 61,706\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 27.07\n",
       "==========================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 3.34\n",
       "Params size (MB): 0.25\n",
       "Estimated Total Size (MB): 3.85\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, \n",
    "                                kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 16, \n",
    "                                kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 120, \n",
    "                                kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.linear1 = nn.Linear(120, 84)\n",
    "        self.linear2 = nn.Linear(84, 10)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.tanh(x)\n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet()\n",
    "x = torch.randn(64,1,32,32)\n",
    "output = model(x)\n",
    "\n",
    "print(model)\n",
    "print(\"output.shape : \",output.shape)\n",
    "summary(model, input_size=(64,1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.3%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
      "\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 14470.7217   60000 / 60000</p>\n",
       "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 8818.8096   60000 / 60000</p>\n",
       "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 7616.4746   60000 / 60000</p>\n",
       "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 7507.0508   60000 / 60000</p>\n",
       "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 7253.2158   60000 / 60000</p>\n",
       "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 7287.0278   60000 / 60000</p>\n",
       "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 7824.0825   60000 / 60000</p>\n",
       "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 7448.4585   60000 / 60000</p>\n",
       "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 7693.5400   60000 / 60000</p>\n",
       "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 7319.3149   60000 / 60000</p>\n",
       "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.12198857963085175\n",
      "Validation loss: 0.19728846848011017\n",
      "Training complete in 1m 39s\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "\n",
    "train_dataset = datasets.MNIST(root='dataset/', train=True, \n",
    "                               transform=transforms.Compose([transforms.Pad(2), transforms.ToTensor()]), download=True)\n",
    "test_dataset = datasets.MNIST(root='dataset/', train=False, \n",
    "                              transform=transforms.Compose([transforms.Pad(2), transforms.ToTensor()]), download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n",
    "dataset_sizes = {'train':len(train_dataset), 'test':len(test_dataset)}\n",
    "\n",
    "model = LeNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "class ProgressMonitor(object):\n",
    "    \"\"\"\n",
    "    Custom IPython progress bar for training\n",
    "    \"\"\"\n",
    "    \n",
    "    tmpl = \"\"\"\n",
    "        <p>Loss: {loss:0.4f}   {value} / {length}</p>\n",
    "        <progress value='{value}' max='{length}', style='width: 100%'>{value}</progress>\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, length):\n",
    "        self.length = length\n",
    "        self.count = 0\n",
    "        self.display = display(self.html(0, 0), display_id=True)\n",
    "        \n",
    "    def html(self, count, loss):\n",
    "        return HTML(self.tmpl.format(length=self.length, value=count, loss=loss))\n",
    "        \n",
    "    def update(self, count, loss):\n",
    "        self.count += count\n",
    "        self.display.update(self.html(self.count, loss))\n",
    "\n",
    "def train_new(model,criterion,optimizer,num_epochs,dataloaders,dataset_sizes,first_epoch=1):\n",
    "    since = time.time() \n",
    "    best_loss = 999999\n",
    "    best_epoch = -1\n",
    "    last_train_loss = -1\n",
    "    plot_train_loss = []\n",
    "    plot_valid_loss = []\n",
    "\n",
    "\n",
    "    for epoch in range(first_epoch, first_epoch + num_epochs):\n",
    "        print(\"\")\n",
    "        print('Epoch', epoch)\n",
    "        running_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        # train phase\n",
    "        model.train()\n",
    "\n",
    "        # create a progress bar\n",
    "        progress = ProgressMonitor(length=dataset_sizes[\"train\"])\n",
    "\n",
    "        for data in dataloaders[0]:\n",
    "            # Move the training data to the GPU\n",
    "            inputs, labels  = data\n",
    "            batch_size = inputs.shape[0]\n",
    "\n",
    "            inputs = Variable(inputs.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "\n",
    "            # clear previous gradient computation\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.data * batch_size\n",
    "            # update progress bar\n",
    "            progress.update(batch_size, running_loss)\n",
    "\n",
    "    epoch_loss = running_loss / dataset_sizes[\"train\"]\n",
    "    print('Training loss:', epoch_loss.item())\n",
    "    plot_train_loss.append(epoch_loss)\n",
    "\n",
    "    # validation phase\n",
    "    model.eval()\n",
    "    # We don't need gradients for validation, so wrap in \n",
    "    # no_grad to save memory\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders[-1]:\n",
    "            inputs, labels  = data\n",
    "            batch_size = inputs.shape[0]\n",
    "\n",
    "            inputs = Variable(inputs.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # calculate the loss\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # update running loss value\n",
    "            valid_loss += loss.data * batch_size\n",
    "\n",
    "    epoch_valid_loss = valid_loss / dataset_sizes[\"test\"]\n",
    "    print('Validation loss:', epoch_valid_loss.item())\n",
    "    plot_valid_loss.append(epoch_valid_loss)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return plot_train_loss, plot_valid_loss, model\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    train_losses, valid_losses, model = train_new(\n",
    "        model = model, criterion = criterion, optimizer = optimizer,\n",
    "        num_epochs=10,dataloaders = [train_loader, test_loader],\n",
    "        dataset_sizes = dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predicted 56673 correctly out of 60000 from training dataset, Acuracy : 94.45\n",
      "Model Predicted 9428 correctly out of 10000 from testing dataset, Acuracy : 94.28\n"
     ]
    }
   ],
   "source": [
    "def accuracy(loader, model, train=True):\n",
    "    num_correct = num_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for data in loader:\n",
    "        inputs, labels  = data\n",
    "        batch_size = inputs.shape[0]\n",
    "        \n",
    "        inputs = Variable(inputs.to(device))\n",
    "        labels = Variable(labels.to(device))\n",
    " \n",
    "        outputs = model(inputs)\n",
    "        _, preds = outputs.max(1)\n",
    "        num_correct += (preds == labels).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    accuracy = (num_correct.item()/num_samples)*100\n",
    "    if train:\n",
    "      print(\"Model Predicted {} correctly out of {} from training dataset, Acuracy : {:.2f}\".format(num_correct.item(), num_samples, accuracy))\n",
    "    else:\n",
    "      print(\"Model Predicted {} correctly out of {} from testing dataset, Acuracy : {:.2f}\".format(num_correct.item(), num_samples, accuracy))\n",
    "    model.train()\n",
    "\n",
    "accuracy(train_loader, model)\n",
    "accuracy(test_loader, model, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
